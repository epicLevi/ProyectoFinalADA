{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Numpy helps with linear algebra operations.\n",
    "import numpy \n",
    "# Scipy.special for the sigmoid function expit().\n",
    "import scipy.special\n",
    "# Library for plotting arrays.\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural network class definition.\n",
    "class neuralNetwork:\n",
    "    \n",
    "    # Initialise the neural network. Equivalent to constructor in C#.\n",
    "    def __init__(self, inputNodes, hiddenNodes, outputNodes, learningrate):\n",
    "        # Set number of nodes in each layer.\n",
    "        self.inputNodes = inputNodes\n",
    "        self.hiddenNodes = hiddenNodes\n",
    "        self.outputNodes = outputNodes\n",
    "        \n",
    "        # Link-weight matrices, weigths_InputToHidden and weigths_HiddenToOutput.\n",
    "        # Weights inside the arrays are w_i_j (Weight sub i sub j), where link is \n",
    "        # from node i in current layer to node j in the next layer.\n",
    "        self.weigths_InputToHidden = numpy.random.normal(0.0, pow(self.inputNodes, -0.5), (self.hiddenNodes, self.inputNodes))\n",
    "        self.weigths_HiddenToOutput = numpy.random.normal(0.0, pow(self.hiddenNodes, -0.5), (self.outputNodes, self.hiddenNodes))\n",
    "\n",
    "        # Learning rate modulates learning speed when optimizing and adjusting\n",
    "        # weight matrices.\n",
    "        self.learningRate = learningrate\n",
    "        \n",
    "        # The activation function is a lambda expretion containing the\n",
    "        # sigmoid function, scipy.special.expit(x).\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        \n",
    "\n",
    "    # Method to train the NeuralNetwork.\n",
    "    def train(self, inputList, targets_list):\n",
    "        # Convert inputs list to 2-dimensinal array.\n",
    "        inputs = numpy.array(inputList, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # Calculate signals into hidden layer, which are the inputs, multiplied\n",
    "        # by the weight matrix from the input to the hidden layer. \n",
    "        inputToHiddenLayer = numpy.dot(self.weigths_InputToHidden, inputs)\n",
    "        # Calculate signals emerging from hidden layer.\n",
    "        outputFromHiddenLayer = self.activation_function(inputToHiddenLayer)\n",
    "        \n",
    "        # Calculate signals into final output layer, which are the outputs from \n",
    "        # the hidden layer, multiplied by the weight matrix from the hidden to\n",
    "        # the final output layer.\n",
    "        inputToFinalLayer = numpy.dot(self.weigths_HiddenToOutput, outputFromHiddenLayer)\n",
    "        # Calculate the signals emerging from final output layer.\n",
    "        outputFromFinalLayer = self.activation_function(inputToFinalLayer)\n",
    "        \n",
    "        # Output layer error is the (target - actual calculated value).\n",
    "        errorsInFinalLayer = targets - outputFromFinalLayer\n",
    "        # Hidden layer error is the errorsInFinalLayer, split by weights, \n",
    "        # then, recombined at hidden nodes.\n",
    "        errorsInHiddenLayer = numpy.dot(self.weigths_HiddenToOutput.T, errorsInFinalLayer) \n",
    "        \n",
    "        # Update the weights for the links between the hidden and output layers.\n",
    "        self.weigths_HiddenToOutput += self.learningRate * numpy.dot((errorsInFinalLayer * outputFromFinalLayer * (1.0 - outputFromFinalLayer)), numpy.transpose(outputFromHiddenLayer))\n",
    "        \n",
    "        # Update the weights for the links between the input and hidden layers.\n",
    "        self.weigths_InputToHidden += self.learningRate * numpy.dot((errorsInHiddenLayer * outputFromHiddenLayer * (1.0 - outputFromHiddenLayer)), numpy.transpose(inputs))\n",
    "        \n",
    "\n",
    "    \n",
    "    # Query the neural network, once it has been trained.\n",
    "    def query(self, inputList):\n",
    "        # Convert inputs list to 2-dimensional array.\n",
    "        inputs = numpy.array(inputList, ndmin=2).T\n",
    "        \n",
    "        # Calculate signals into hidden layer.\n",
    "        inputToHiddenLayer = numpy.dot(self.weigths_InputToHidden, inputs)\n",
    "        # Calculate the signals emerging from hidden layer.\n",
    "        outputFromHiddenLayer = self.activation_function(inputToHiddenLayer)\n",
    "        \n",
    "        # Calculate signals into final output layer.\n",
    "        inputToFinalLayer = numpy.dot(self.weigths_HiddenToOutput, outputFromHiddenLayer)\n",
    "        # Calculate the signals emerging from final output layer.\n",
    "        outputFromFinalLayer = self.activation_function(inputToFinalLayer)\n",
    "        \n",
    "        return outputFromFinalLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 784 input nodes, one for each pixel in a digit.\n",
    "input_nodes = 784\n",
    "# 300 nodes, \n",
    "hidden_nodes = 200\n",
    "# 10 nodes, one for each number from 0 to 9.\n",
    "output_nodes = 10\n",
    "\n",
    "# Learning rate, moderates learning, so no neuron over-fits to no sample.\n",
    "learning_rate = 0.1\n",
    "\n",
    "nn = neuralNetwork(input_nodes, hidden_nodes, output_nodes, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the mnist training data CSV file into a list\n",
    "training_data_file = open(\"mnist_train_100.csv\", 'r')\n",
    "training_data_list = training_data_file.readlines()\n",
    "training_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for record in training_data_list:\n",
    "        all_values = record.split(',')\n",
    "        # Scale and shift the inputs for them to be in a range of (0, 1). \n",
    "        inputs = (numpy.asfarray(all_values[1:]) / 255.0 * 0.99) + 0.01\n",
    "        # Create the target output values.\n",
    "        targets = numpy.zeros(output_nodes) + 0.01\n",
    "        # all_values[0] is the target label for this record, \n",
    "        # meaning, the right value.\n",
    "        targets[int(all_values[0])] = 0.99\n",
    "        nn.train(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load testing data CSV file into a list.\n",
    "test_data_file = open(\"mnist_test_10.csv\", 'r')\n",
    "test_data_list = test_data_file.readlines()\n",
    "test_data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = test_data_list[0].split(',')\n",
    "# Reshape array of 784 as a matrix of 28 x 28.\n",
    "image_array = numpy.asfarray(all_values[1:]).reshape((28,28))\n",
    "# Display this digit graphically. \n",
    "matplotlib.pyplot.imshow(image_array, cmap = 'Greys', interpolation = 'None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.query((numpy.asfarray(all_values[1:]) / 255 * 0.99) + 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
